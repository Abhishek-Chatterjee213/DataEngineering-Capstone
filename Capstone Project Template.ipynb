{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "`This project aims to be able to answers questions on US immigration such as what are the most popular cities for immigration, what is the gender distribution of the immigrants, what is the visa type distribution of the immigrants, what is the average age per immigrant and what is the average temperature per month per city. We extract data from 3 different sources, the I94 immigration dataset of 2016, city temperature data from Kaggle and US city demographic data from OpenSoft. We design 4 dimension tables: Cities, immigrants, monthly average city temperature and time, and 1 fact table: Immigration. We use Spark for ETL jobs and store the results in parquet for downstream analysis.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, udf, year, month, avg, round, dayofweek, weekofyear, isnull\n",
    "from pyspark.sql.types import StringType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "1.1 Scope\n",
    "\n",
    "`The goal of this project is pull data from 3 different sources and create fact and dimension table to be able to do analysis on US immigration using factors of city monthly average temperature, city demographics and seasonality.`\n",
    "\n",
    "1.2 Data Soures\n",
    "\n",
    "    * I94 Immigration Data: `comes from the U.S. National Tourism and Trade Office and contains various statistics on international visitor arrival in USA and comes from the US National Tourism and Trade Office. The dataset contains data from 2016.`\n",
    "    * World Temperature Data: `comes from Kaggle and contains average weather temperatures by city.`\n",
    "    * U.S. City Demographic Data: `comes from OpenSoft and contains information about the demographics of all US cities such as average age, male and female population.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "# Read i94 data\n",
    "i94_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "# Read temparature data\n",
    "temperature_df = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")\n",
    "# Read demographics data\n",
    "demo_df = spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load(\"us-cities-demographics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing cleaning tasks here\n",
    "i94_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop nas\n",
    "cleaned_i94_df = i94_df.dropna(how=\"any\", subset=[\"i94port\", \"i94addr\", \"gender\",\"i94mode\"])\n",
    "\n",
    "# Drop non us immigration data\n",
    "\n",
    "cleaned_i94_df = cleaned_i94_df.filter(cleaned_i94_df.i94addr != 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get valid states from demographics data\n",
    "valid_states = demo_df.toPandas()[\"State Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Validate states in i94 data\n",
    "@udf(StringType())\n",
    "def validate_state(x):  \n",
    "    if x in valid_states:\n",
    "        return x\n",
    "    return 'other'\n",
    "\n",
    "cleaned_i94_df = cleaned_i94_df.withColumn(\"i94addr\", validate_state(cleaned_i94_df.i94addr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert sas date format\n",
    "@udf(StringType())\n",
    "def convert_datetime(x):\n",
    "    if x:\n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None\n",
    "\n",
    "cleaned_i94_df = cleaned_i94_df.withColumn(\"arrdate\", convert_datetime(cleaned_i94_df.arrdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert to staging table schema\n",
    "\n",
    "staging_i94_df = cleaned_i94_df.select(col(\"cicid\").alias(\"immigrant_id\"), \n",
    "                                       col(\"arrdate\").alias(\"date\"),\n",
    "                                       col(\"i94port\").alias(\"city_code\"),\n",
    "                                       col(\"i94addr\").alias(\"state_code\"),\n",
    "                                       col(\"I94res\").alias(\"resident_country\"),\n",
    "                                       col(\"i94bir\").alias(\"age\"),\n",
    "                                       col(\"gender\").alias(\"gender\"),\n",
    "                                       col(\"i94visa\").alias(\"visa_type\"),\"count\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Temparature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Clean temparature data to have only valid cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get city, state and visa type maaping from SAS data label\n",
    "i94_sas_label_descriptions_fname= \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "with open(i94_sas_label_descriptions_fname) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = []\n",
    "valid_states = []\n",
    "visa_types = []\n",
    "country_map = []\n",
    "valid_ports_map = {}\n",
    "\n",
    "for line in lines[10:298]:\n",
    "    country_code = line.split(\"=\")[0].strip()\n",
    "    country_name = line.split(\"=\")[1].strip()\n",
    "    country_map.append({\"country_code\":country_code, \"country_name\": country_name})\n",
    "    \n",
    "for line in lines[302:961]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_ports.append({\"city_code\":results.group(1), \"city_name\":results.group(2).strip()})\n",
    "    valid_ports_map[results.group(1).strip()] = results.group(2).strip()\n",
    "    \n",
    "for line in lines[982:1036]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_states.append({\"state_code\":results.group(1).strip(), \"state_name\" : results.group(2).strip()})\n",
    "    \n",
    "for line in lines[1046:1049]:\n",
    "    visa_type = line.split(\"=\")[0].strip()\n",
    "    visa_desc = line.split(\"=\")[1].strip()\n",
    "    visa_types.append({\"visa_code\":visa_type, \"visa_desc\": visa_desc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    }
   ],
   "source": [
    "# Convert state mappning to df\n",
    "dim_port_map = spark.createDataFrame(valid_ports, schema=[\"country_code\",\"country_name\"])\n",
    "\n",
    "# Convert state mapping to df\n",
    "dim_state_map = spark.createDataFrame(valid_states, schema=[\"state_code\",\"state_name\"])\n",
    "\n",
    "# Convert visa mapping to df\n",
    "dim_visa_map = spark.createDataFrame(visa_types, schema = [\"visa_code\", \"visa_desc\"])\n",
    "\n",
    "# Convert to country df\n",
    "\n",
    "dim_country_map = spark.createDataFrame(country_map, schema = [\"country_code\", \"country_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter temparature data using udf\n",
    "\n",
    "@udf(StringType())\n",
    "def city_to_port(city):\n",
    "    for key in valid_ports_map:\n",
    "        if city.lower() in valid_ports_map[key].lower():\n",
    "            return key\n",
    "        \n",
    "cleaned_temp_df = temperature_df.filter(temperature_df[\"Country\"] == \"United States\") \\\n",
    "    .withColumn(\"year\", year(temperature_df['dt'])) \\\n",
    "    .withColumn(\"month\", month(temperature_df[\"dt\"])) \\\n",
    "    .withColumn(\"i94port\", city_to_port(temperature_df[\"City\"])) \\\n",
    "    .withColumn(\"AverageTemperature\", col(\"AverageTemperature\").cast(\"float\")) \\\n",
    "    .dropna(how='any', subset=[\"i94port\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert to staging table structure\n",
    "staging_temp_df = cleaned_temp_df.select(col(\"year\"), col(\"month\"), col(\"i94port\").alias(\"city_code\"),\n",
    "                                         round(col(\"AverageTemperature\"), 1).alias(\"avg_temperature\"),\n",
    "                                         col(\"Latitude\").alias(\"lat\"), col(\"Longitude\").alias(\"long\")).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate percentages of numeric columns and create new ones\n",
    "cleaned_demo_df = demo_df.withColumn(\"median_age\", demo_df['Median Age']) \\\n",
    "    .withColumn(\"pct_male_pop\", (demo_df['Male Population'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_female_pop\", (demo_df['Female Population'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_veterans\", (demo_df['Number of Veterans'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_foreign_born\", (demo_df['Foreign-born'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_race\", (demo_df['Count'] / demo_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"city_code\", city_to_port(demo_df[\"City\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])\n",
    "\n",
    "cleaned_demo_df = cleaned_demo_df.select(col(\"City\").alias(\"city_name\"), col(\"State Code\").alias(\"state_code\"), \n",
    "                         \"median_age\", \"pct_male_pop\", \"pct_female_pop\",\"pct_veterans\", \n",
    "                         \"pct_foreign_born\", col(\"Total Population\").alias(\"total_pop\"), \n",
    "                         col(\"Race\").alias(\"race\"), \"pct_race\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Pivot table based on race \n",
    "pivot_demo_df = cleaned_demo_df.groupBy(\"city_name\",\"state_code\", \"median_age\", \"pct_male_pop\",\n",
    "                                        \"pct_female_pop\",\"pct_veterans\", \"pct_foreign_born\", \"total_pop\").pivot(\"Race\").avg(\"pct_race\")\n",
    "\n",
    "pivot_demo_df = pivot_demo_df.withColumn(\"city_code\", city_to_port(pivot_demo_df[\"city_name\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Convert to staging structure \n",
    "\n",
    "\n",
    "staging_demo_df = pivot_demo_df.select(\"city_code\", \"state_code\", \"median_age\",\n",
    "                                    round(col(\"pct_male_pop\"), 1).alias(\"pct_male_pop\"),\n",
    "                                    round(col(\"pct_female_pop\"), 1).alias(\"pct_female_pop\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_veterans\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_foreign_born\"),\n",
    "                                    round(col(\"American Indian and Alaska Native\"), 1).alias(\"pct_native_american\"),\n",
    "                                    round(col(\"Asian\"), 1).alias(\"pct_asian\"),\n",
    "                                    round(col(\"Black or African-American\"), 1).alias(\"pct_black\"),\n",
    "                                    round(col(\"Hispanic or Latino\"), 1).alias(\"pct_hispanic_or_latino\"),\n",
    "                                    round(col(\"White\"), 1).alias(\"pct_white\"), \"total_pop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "The star schema is chosen as the data model because it is simple and yet effective. users can write simple queries by joing fact and dimension tables to analyze the data.\n",
    "\n",
    "Here are the tables of the schema:\n",
    "\n",
    "1. Staging Tables\n",
    "    * staging_i94_df\n",
    "    \n",
    "    `id\n",
    "    date\n",
    "    city_code\n",
    "    state_code\n",
    "    age\n",
    "    gender\n",
    "    visa_type\n",
    "    count`\n",
    "\n",
    "    * staging_temp_df\n",
    "    \n",
    "    `year\n",
    "    month\n",
    "    city_code\n",
    "    city_name\n",
    "    avg_temperature\n",
    "    lat\n",
    "    long`\n",
    "\n",
    "    * staging_demo_df\n",
    "     \n",
    "    `city_code\n",
    "    state_code\n",
    "    median_age\n",
    "    pct_male_pop\n",
    "    pct_female_pop\n",
    "    pct_veterans\n",
    "    pct_foreign_born\n",
    "    pct_native_american\n",
    "    pct_asian\n",
    "    pct_black\n",
    "    pct_hispanic_or_latino\n",
    "    pct_white\n",
    "    total_pop`\n",
    "    \n",
    "2. Dimension Tables\n",
    "\n",
    "   * dim_demos        \n",
    "     `city_code\n",
    "      state_code\n",
    "      city_name\n",
    "      median_age\n",
    "      pct_male_pop\n",
    "      pct_female_pop\n",
    "      pct_veterans\n",
    "      pct_foreign_born\n",
    "      pct_native_american\n",
    "      pct_asian\n",
    "      pct_black\n",
    "      pct_hispanic_or_latino\n",
    "      pct_white\n",
    "      total_pop\n",
    "      lat\n",
    "      long`\n",
    "        \n",
    "   * dim_monthly_city_temp\n",
    "        \n",
    "     `city_code\n",
    "      year\n",
    "      month\n",
    "      avg_temperature`\n",
    "\n",
    "   * dim_time\n",
    "         \n",
    "     `date\n",
    "     dayofweek\n",
    "     weekofyear\n",
    "     month`\n",
    "         \n",
    "   * dim_country\n",
    "          \n",
    "      `country_code\n",
    "       country_name`\n",
    "      \n",
    "   * dim_states\n",
    "    \n",
    "      `state_code\n",
    "       state_name`\n",
    "       \n",
    "   * dim_city\n",
    "   \n",
    "       `city_code\n",
    "       city_name`\n",
    "           \n",
    "3. Fact Table\n",
    "    * immigration_df\n",
    "        \n",
    "        `immigrant_id\n",
    "        state_code\n",
    "        city_code\n",
    "        resident_country\n",
    "        date\n",
    "        age\n",
    "        gender\n",
    "        visa_type\n",
    "        count`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "1. Clean the data on nulls, data types, duplicates, etc\n",
    "2. Load staging tables for staging_i94_df, staging_temp_df and staging_demo_df\n",
    "3. Create dimension tables\n",
    "4. Create fact table ensuring referential integrity\n",
    "6. Save processed dimension and fact tables in parquet for downstream query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dimenssion tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dimenssion table for immigrants\n",
    "\n",
    "immigrant_df = staging_i94_df.select(\"immigrant_id\", \"gender\", \"age\", \"visa_type\").drop_duplicates()\n",
    "\n",
    "#Dimenssion table for city\n",
    "\n",
    "city_df = staging_demo_df.join(staging_temp_df, \"city_code\") \\\n",
    "    .select(\"city_code\", \"state_code\", \"median_age\", \"pct_male_pop\", \"pct_female_pop\", \"pct_veterans\",\n",
    "           \"pct_foreign_born\", \"pct_native_american\", \"pct_asian\", \"pct_black\",\n",
    "           \"pct_hispanic_or_latino\", \"pct_white\", \"total_pop\", \"lat\", \"long\").drop_duplicates()\n",
    "\n",
    "# Dimenssion table for temparature\n",
    "\n",
    "monthly_city_temp_df = staging_temp_df.select(\"city_code\", \"year\", \"month\", \"avg_temperature\").drop_duplicates()\n",
    "\n",
    "#Dimenssion table for time\n",
    "\n",
    "time_df = staging_i94_df.withColumn(\"dayofweek\", dayofweek(\"date\"))\\\n",
    "                .withColumn(\"weekofyear\", weekofyear(\"date\"))\\\n",
    "                .withColumn(\"month\", month(\"date\"))\n",
    "                        \n",
    "time_df = time_df.select(\"date\", \"dayofweek\", \"weekofyear\", \"month\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Dimenssion table for city\n",
    "\n",
    "dim_demos = staging_demo_df.join(staging_temp_df, \"city_code\") \\\n",
    "    .select(\"city_code\", \"state_code\", \"median_age\", \"pct_male_pop\", \"pct_female_pop\", \"pct_veterans\",\n",
    "           \"pct_foreign_born\", \"pct_native_american\", \"pct_asian\", \"pct_black\",\n",
    "           \"pct_hispanic_or_latino\", \"pct_white\", \"total_pop\", \"lat\", \"long\").drop_duplicates()\n",
    "\n",
    "# Dimenssion table for temparature\n",
    "\n",
    "dim_monthly_city_temp = staging_temp_df.select(\"city_code\", \"year\", \"month\", \"avg_temperature\").drop_duplicates()\n",
    "\n",
    "#Dimenssion table for time\n",
    "\n",
    "time_df = staging_i94_df.withColumn(\"dayofweek\", dayofweek(\"date\"))\\\n",
    "                .withColumn(\"weekofyear\", weekofyear(\"date\"))\\\n",
    "                .withColumn(\"month\", month(\"date\"))\n",
    "                        \n",
    "dim_time = time_df.select(\"date\", \"dayofweek\", \"weekofyear\", \"month\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write to dim_demos\n",
    "dim_demos.coalesce(1).write.mode(\"overwrite\").partitionBy(\"state_code\",\"city_code\").parquet(\"sparkify/dim_demos\")\n",
    "\n",
    "# Write to dim_monthly_city_tempearture\n",
    "dim_monthly_city_temp.coalesce(1).write.mode(\"overwrite\").parquet(\"sparkify/dim_monthly_city_temperature\")\n",
    "\n",
    "# Write to dim_time\n",
    "dim_time.coalesce(1).write.mode(\"overwrite\").parquet(\"sparkify/dim_time\")\n",
    "\n",
    "# Write to dim_country \n",
    "dim_port_map.coalesce(1).write.mode(\"overwrite\").parquet(\"sparkify/dim_city\")\n",
    "\n",
    "# Write to dim_states\n",
    "dim_state_map.coalesce(1).write.mode(\"overwrite\").parquet(\"sparkify/dim_state\")\n",
    "\n",
    "# Write to dim_visa\n",
    "dim_visa_map.coalesce(1).write.mode(\"overwrite\").parquet(\"sparkify/dim_visa\")\n",
    "\n",
    "# Write to dim_country\n",
    "dim_country_map.coalesce(1).write.mode(\"overwrite\").parquet(\"sparkify/dim_country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fact table for immigration\n",
    "fact_immigration = staging_i94_df.select(\"immigrant_id\", \"gender\", \"age\", \"visa_type\", \"resident_country\", \"city_code\",\"state_code\",\"date\",\"count\") .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write fact table\n",
    "fact_immigration.coalesce(1).write.mode(\"overwrite\").partitionBy(\"resident_country\",\"state_code\",\"city_code\").parquet(\"sparkify/fact_immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data quality check passed\n",
      "dimension tables and fact table exist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if table exsists\n",
    "\n",
    "def table_exists(df):\n",
    "    if df is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "if table_exists(dim_demos) & table_exists(dim_monthly_city_temp) & table_exists(dim_time) & table_exists(fact_immigration) & table_exists(dim_port_map) & table_exists(dim_state_map) & table_exists(dim_country_map):\n",
    "    print(\"data quality check passed\")\n",
    "    print(\"dimension tables and fact table exist\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"data quality check failed\")\n",
    "    print(\"table missing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check all tables have data\n",
    "\n",
    "def table_not_empty(df):\n",
    "    return df.count() != 0 \n",
    "\n",
    "if table_not_empty(dim_demos) & table_not_empty(dim_monthly_city_temp) & table_not_empty(dim_time) & table_not_empty(fact_immigration)  & table_not_empty(dim_port_map) & table_not_empty(dim_state_map) & table_not_empty(dim_country_map):\n",
    "    print(\"data quality check passed!\")\n",
    "    print(\"dimension tables and fact table contain records\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"data quality check failed!\")\n",
    "    print(\"null records...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "1. ER Diagram \n",
    "\n",
    "    <img src=\"img/erd.PNG\">\n",
    "\n",
    "1. Dimension Tables\n",
    "\n",
    "    * dim_demos - This holds data about a city e.g - city_name, state, population details (median_age, percentage of male & female etc)\n",
    "        \n",
    "        `city_code: city port code --> primary key\n",
    "        state_code: state code of the city --> partition key\n",
    "        median_age: median age of the city\n",
    "        pct_male_pop: city's male population in percentage\n",
    "        pct_female_pop: city's female population in percentage\n",
    "        pct_veterans: city's veteran population in percentage\n",
    "        pct_foreign_born: city's foreign born population in percentage\n",
    "        pct_native_american: city's native american population in percentage\n",
    "        pct_asian: city's asian population in percentage\n",
    "        pct_black: city's black population in percentage\n",
    "        pct_hispanic_or_latino: city's hispanic or latino population in percentage\n",
    "        pct_white: city's white population in percentage\n",
    "        total_pop: city's total population\n",
    "        lat: latitude of the city\n",
    "        long: longitude of the city`\n",
    "\n",
    "    * dim_monthly_temperature_by_city - This holds temparature data for a city.\n",
    "        \n",
    "        `city_code: city port code --> Foreign Key References dim_cities\n",
    "        year: year\n",
    "        month: month \n",
    "        avg_temperature: average temperature in city for given month`\n",
    "\n",
    "    * dim_time - Holds details of a day.\n",
    "        \n",
    "        `date: date --> primary key\n",
    "        dayofweek: day of the week\n",
    "        weekofyear: week of year\n",
    "        month: month`\n",
    "        \n",
    "    * dim_country - Holds country mapping\n",
    "          \n",
    "      `country_code : country code --> Primary Key\n",
    "       country_name: Country Name`\n",
    "      \n",
    "   * dim_states - Holds state_code to state mapping\n",
    "    \n",
    "      `state_code : Stqte Code --> Primary Key\n",
    "       state_name : State Name`\n",
    "       \n",
    "   * dim_city - Holds city_code to city_name mapping\n",
    "   \n",
    "       `city_code : City Code --> Primary Key\n",
    "       city_name : City Name`\n",
    "       \n",
    "   * dim_visa - Holds Visa type to visa description mapping\n",
    "       \n",
    "       `visa_code: Visa Code --> Primary Key\n",
    "       visa_desc: Visa Description`\n",
    "        \n",
    "2. Fact Table\n",
    "    * fact_immigration - Fact table where the foreign keys are taken from different dimenssion tables and stores the count of immigrants entered in us.\n",
    "        \n",
    "     `immigrant_id: id --> Primary Key\n",
    "      state_code: --> state code of arrival city Foreign Key dim_state\n",
    "      city_code: city port code of arrival city --> Foreign Key REFERENCES dim_city\n",
    "      resident_country: Country of residence --> Foreign Key References dim_city\n",
    "      date: date of arrival --> Foreign Key REFERENCES dim_time\n",
    "      age : Age\n",
    "      gender: Gender\n",
    "      visa_type: Visa Type\n",
    "      count: count of immigrant's entries into the US`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Spark is chosen here as the data processing framework as it has capability of processing large distributed data efficiently. Apart from that spark has a wide variety of read, write and data processing transformations available for different file formats and filesystems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are also considerations in terms of scaling existing solution.\n",
    "\n",
    "1. If the data was increased by 100x: \n",
    "\n",
    "    `We can cosider having large scale emr set up or setting up spark on Kubernetes so that we can make use of vertical and horizontal scalings.`\n",
    "\n",
    "    `Also, we might consider using Cassandra as a temprary storage which is higly available and provides pretty fast write speed. From there we can load our DW dbs as required.`\n",
    "\n",
    "2. If the data populates a dashboard that must be updated on a daily basis by 7am every day: \n",
    "\n",
    "    `We can consider using Airflow or Kubeflow to schedule and automate the data pipeline jobs. We can set up prometheus and grafana to do automatic alerting based on specific conditions as well as retrying the failed jobs.`\n",
    "\n",
    "3. If the database needed to be accessed by 100+ people: \n",
    "\n",
    "    `We can consider hosting our solution in production scale data warehouse in the cloud, with larger capacity to serve more users, and workload management to ensure equitable usage of resources across users.`\n",
    "    \n",
    "4. If there is a chance the data structure can change in future :\n",
    "    ` We can use a data cataloging tool like AWS glue to manage and maintain the schema.`\n",
    "    \n",
    "5. If Raw & Unstructured Data access is needed:\n",
    "\n",
    "    `Desigining a data lake with AWS Glue can be a good option along with Querying via AWS Athena / Apache Drill.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
